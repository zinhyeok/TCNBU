import numpy as np
import torch
from typing import List, Tuple, Dict, Optional, Any
from math import ceil, log2, floor
from itertools import chain

# í—¬í¼ í•¨ìˆ˜ ë° í´ë˜ìŠ¤ëŠ” ë³„ë„ íŒŒì¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì„¤ëª…ì„ ìœ„í•´ í•¨ê»˜ ì •ì˜í•©ë‹ˆë‹¤.
# ì‹¤ì œ êµ¬í˜„ ì‹œ utils/r_utils.py, models/model_selector.py ë“±ìœ¼ë¡œ ë¶„ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
from utils.r_utils import compute_g_stat_from_graph  # R gSeg í˜¸ì¶œ í•¨ìˆ˜ (ê°€ì •)
# from models.model_selector import ModelSelector # ìµœì¢… CP ì„ íƒ ë¡œì§ (ê°€ì •)


@dataclass
class CPStat:
    """Change Pointì™€ G-í†µê³„ëŸ‰ ìŒì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    cp: int
    G: float
    window_indices: List[List[int]] # ì–´ë–¤ ìœˆë„ìš°ì—ì„œ ê³„ì‚°ë˜ì—ˆëŠ”ì§€ ì¶”ì 

class gBottomup:
    """
    TCN ì¸ì½”ë”ì™€ ìœ ê¸°ì ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ì ì‘í˜• ì˜¨ë¼ì¸ í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” gBottomup ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤.
    """
    def __init__(self, encoder: torch.nn.Module, config: Dict[str, Any]):
        """
        Args:
            encoder (torch.nn.Module): TCN ì¸ì½”ë” ëª¨ë¸ ê°ì²´.
            config (Dict[str, Any]): í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„¤ì •ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬.
        """
        self.encoder = encoder
        self.config = config
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.encoder.to(self.device)

        # ì„¤ì • ê°’ë“¤ì„ í´ë˜ìŠ¤ ì†ì„±ìœ¼ë¡œ ì €ì¥
        self.min_obs = config.get('min_obs', 4)
        self.merge_percentile = config.get('merge_percentile', 0.1)
        self.graph_type = config.get('graph_type', 'mst')
        self.k_max = config.get('k_max', 5) # ê·¸ë˜í”„ ìƒì„± ì‹œ ìµœëŒ€ kê°’

        # íƒìƒ‰ ê³¼ì •ì„ ê¸°ë¡í•  íˆìŠ¤í† ë¦¬
        self.seg_history: List[List[List[int]]] = []
        self.merge_history: List[List[CPStat]] = []
        
        self.observations: Optional[np.ndarray] = None

    def set_encoder(self, encoder: torch.nn.Module):
        """ì™¸ë¶€(Trainer)ì—ì„œ ì—…ë°ì´íŠ¸ëœ ì¸ì½”ë”ë¥¼ ì£¼ì…ë°›ê¸° ìœ„í•œ ë©”ì†Œë“œ."""
        self.encoder = encoder
        self.encoder.to(self.device)

    def _embed_data(self, window_data: np.ndarray) -> np.ndarray:
        """ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í˜„ì¬ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•´ ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        self.encoder.eval()
        with torch.no_grad():
            # (Length, Channels) -> (1, Length, Channels)
            tensor_data = torch.from_numpy(window_data).float().unsqueeze(0).to(self.device)
            # ì¸ì½”ë”ëŠ” (B, L, C_emb) í˜•íƒœì˜ í¬ì¸íŠ¸ë³„ ì„ë² ë”©ì„ ë°˜í™˜
            embedded_tensor = self.encoder(tensor_data)
            # (1, L, C_emb) -> (L, C_emb)
            return embedded_tensor.squeeze(0).cpu().numpy()

    def _build_graph(self, observations: np.ndarray) -> np.ndarray:
        """
        (ì„ë² ë”©ëœ) ê´€ì¸¡ê°’ìœ¼ë¡œë¶€í„° k-MST ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ê³  ì—£ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        (gBottomup_R_unmerge.pyì˜ build_graph ë¡œì§ì„ ë‹¨ìˆœí™”í•˜ì—¬ í†µí•©)
        """
        # ì´ ë¶€ë¶„ì€ gBottomup_R_unmerge.pyì˜ build_graph ë¡œì§ì„ ê°€ì ¸ì™€ êµ¬í˜„í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” í•µì‹¬ ë¡œì§ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ê°œë…ì ì¸ ì½”ë“œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
        from sklearn.metrics.pairwise import euclidean_distances
        from scipy.sparse.csgraph import minimum_spanning_tree

        n_obs = observations.shape[0]
        k = min(self.k_max, (n_obs // 2) - 1, int(np.sqrt(n_obs)))
        k = max(1, k)
        
        dist_matrix = euclidean_distances(observations)
        
        # k-MST ìƒì„± ë¡œì§ (ê°„ëµí™”)
        # ì‹¤ì œë¡œëŠ” ëˆ„ì  ì—£ì§€ë¥¼ ê´€ë¦¬í•´ì•¼ í•¨
        mst = minimum_spanning_tree(dist_matrix)
        rows, cols = mst.nonzero()
        
        # Rê³¼ í˜¸í™˜ë˜ë„ë¡ 1-based ì¸ë±ì‹±ìœ¼ë¡œ ë³€í™˜
        edges = np.array(list(zip(rows, cols)), dtype=int) + 1
        return edges

    def compute_g(self, window_indices: List[List[int]]) -> CPStat:
        """
        ì£¼ì–´ì§„ ìœˆë„ìš°ì— ëŒ€í•´ ì„ë² ë”© ë³€í™˜ í›„ G-í†µê³„ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        # 1. ì›ë³¸ ë°ì´í„° ì¶”ì¶œ
        flat_indices = list(chain.from_iterable(window_indices))
        window_data = self.observations[flat_indices, :]

        # 2. ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ë³€í™˜ ğŸ”¥
        embedded_data = self._embed_data(window_data)

        # 3. ì„ë² ë”© ê³µê°„ì—ì„œ ê·¸ë˜í”„ ìƒì„±
        edges = self._build_graph(embedded_data)
        
        # 4. G-í†µê³„ëŸ‰ ê³„ì‚° (R í—¬í¼ í•¨ìˆ˜ í˜¸ì¶œ)
        n_obs = len(flat_indices)
        t_split = len(window_indices[0]) - 1 # 0-based ë¶„í• ì 
        
        g_stat = compute_g_stat_from_graph(n_obs, edges, t_split)

        # 5. ê²°ê³¼ ë°˜í™˜
        change_point_index = flat_indices[t_split]
        return CPStat(cp=change_point_index, G=g_stat, window_indices=window_indices)

    def _select_merge_candidates(self, stats: List[CPStat]) -> List[int]:
        """G-í†µê³„ëŸ‰ ìˆœìœ„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•  ìœˆë„ìš°ì˜ ì¸ë±ìŠ¤ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
        if not stats:
            return []
        
        n = len(stats)
        k = ceil(n * self.merge_percentile) if n > 0 else 0
        if k == 0 and n > 1: k = 1 # ìµœì†Œ 1ê°œëŠ” ë³‘í•©
        
        # G-ê°’ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìƒìœ„ kê°œ ì„ íƒ
        sorted_indices = sorted(range(n), key=lambda i: stats[i].G)
        return sorted_indices[:k]

    def fit(self, data: np.ndarray):
        """
        ì ì‘í˜• ì˜¨ë¼ì¸ í•™ìŠµì„ ìœ„í•œ fit ë©”ì†Œë“œ.
        Trainerì— ì˜í•´ ì œì–´ë˜ë©°, M ìŠ¤í…ë§ˆë‹¤ ê¸ì • ìŒì„ yieldí•©ë‹ˆë‹¤.
        """
        self.observations = data
        n, d = data.shape

        # ì´ˆê¸° ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
        seg_idx = [list(range(i, min(i + self.min_obs, n))) for i in range(0, n, self.min_obs)]
        self.seg_history.append([s.copy() for s in seg_idx])

        # ì‚¬ì „ Unmerge ë‹¨ê³„ (í•„ìš” ì‹œ ì¶”ê°€)
        # num_unmerge_steps = floor(log2(n))
        # for _ in range(num_unmerge_steps):
        #     seg_idx = self._perform_unmerge_pass(seg_idx)
        # self.seg_history.append([seg.copy() for seg in seg_idx])

        # ë©”ì¸ íƒìƒ‰-í•™ìŠµ ë£¨í”„ (ì™¸ë¶€ Trainerê°€ ì œì–´)
        while len(seg_idx) > 1:
            # 1. í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡°ë¡œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±
            # (gBottomup_R_unmerge.pyì˜ sliding_windows ë¡œì§ ì‚¬ìš©)
            all_windows = self._create_sliding_windows(seg_idx)
            if not all_windows: break

            # 2. ëª¨ë“  ìœˆë„ìš°ì— ëŒ€í•´ G-í†µê³„ëŸ‰ ê³„ì‚°
            current_stats = [self.compute_g(win) for win in all_windows]
            self.merge_history.append(current_stats)

            # 3. ë³‘í•©í•  í›„ë³´ ìœˆë„ìš° ì„ íƒ
            candidate_indices = self._select_merge_candidates(current_stats)
            if not candidate_indices: break
            
            # 4. ì„ íƒëœ í›„ë³´ë“¤ì„ ê¸ì • ìŒìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ yield
            positive_pairs = [current_stats[i].window_indices for i in candidate_indices]
            
            # ğŸ”¥ Trainerì—ê²Œ ê¸ì • ìŒì„ ì „ë‹¬í•˜ê³ , ì—…ë°ì´íŠ¸ëœ ì¸ì½”ë”ë¥¼ ê¸°ë‹¤ë¦¼
            new_encoder = yield positive_pairs
            if new_encoder is not None:
                self.set_encoder(new_encoder)

            # 5. ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ìˆ˜í–‰
            # (gBottomup_R_unmerge.pyì˜ merge_segments_sequential ë¡œì§ ì‚¬ìš©)
            seg_idx = self._merge_segments(all_windows, candidate_indices)
            self.seg_history.append([s.copy() for s in seg_idx])
            
            # í›„-ë³‘í•© Unmerge ë‹¨ê³„ (í•„ìš” ì‹œ ì¶”ê°€)
            # seg_idx = self._perform_unmerge_pass(seg_idx)
            # self.seg_history.append([seg.copy() for seg in seg_idx])
            
        # ìµœì¢… ë³€í™”ì  ì„ íƒ ë¡œì§ (ModelSelector ë“± ì‚¬ìš©)
        # final_cps = ModelSelector(self).select_final_cps()
        # return final_cps
        return self.merge_history # ì„ì‹œë¡œ ì „ì²´ íˆìŠ¤í† ë¦¬ ë°˜í™˜

    # ì•„ë˜ëŠ” gBottomup_R_unmerge.pyì—ì„œ ê°€ì ¸ì™€ì•¼ í•  í—¬í¼ ë©”ì†Œë“œë“¤ì…ë‹ˆë‹¤.
    # ì„¤ëª…ì„ ìœ„í•´ ì‹œê·¸ë‹ˆì²˜ë§Œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
    def _create_sliding_windows(self, seg_idx: List[List[int]]) -> List[List[List[int]]]:
        # ... gBottomup_R_unmerge.pyì˜ sliding_windows êµ¬í˜„ ...
        windows = []
        n = len(seg_idx)
        for i in range(n - 1):
            windows.append([seg_idx[i], seg_idx[i+1]])
        return windows

    def _merge_segments(self, all_windows: List[List[List[int]]], indices_to_merge: List[int]) -> List[List[int]]:
        # ... gBottomup_R_unmerge.pyì˜ merge_segments_sequential êµ¬í˜„ ...
        
        # ë³‘í•©ë  ìœˆë„ìš°ë“¤ì„ G-ê°’ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (gBottomup_R_unmerge.py ì°¸ì¡°)
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ë³‘í•©
        
        segments_to_merge_set = set()
        for i in indices_to_merge:
            win = all_windows[i]
            segments_to_merge_set.add(tuple(map(tuple, win)))
        
        merged_segments = []
        used_segments = set()
        
        # 1. ë³‘í•©ë˜ì§€ ì•ŠëŠ” ì„¸ê·¸ë¨¼íŠ¸ ìœ ì§€
        current_segments = list(chain.from_iterable(all_windows))
        final_segments = []
        
        # ì´ ë¶€ë¶„ì€ merge_segments_sequentialì˜ ì •í™•í•œ ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.
        # ì•„ë˜ëŠ” ê°œë…ì ì¸ êµ¬í˜„ì…ë‹ˆë‹¤.
        
        all_base_segments = {tuple(s) for s in list(chain.from_iterable(all_windows))}
        
        newly_created = []
        removed = set()

        for i in indices_to_merge:
            window_to_merge = all_windows[i]
            
            seg_ A_tuple = tuple(window_to_merge[0])
            seg_B_tuple = tuple(window_to_merge[1])

            if seg_A_tuple in removed or seg_B_tuple in removed:
                continue

            merged = sorted(list(set(chain.from_iterable(window_to_merge))))
            newly_created.append(merged)
            removed.add(seg_A_tuple)
            removed.add(seg_B_tuple)

        final_segments = [list(s) for s in all_base_segments if s not in removed]
        final_segments.extend(newly_created)
        
        return sorted(final_segments, key=lambda x: x[0])


    def _perform_unmerge_pass(self, seg_idx: List[List[int]]) -> List[List[int]]:
        # ... gBottomup_R_unmerge.pyì˜ _perform_unmerge_pass êµ¬í˜„ ...
        # ì´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œë„ self.compute_gë¥¼ í˜¸ì¶œí•´ì•¼ í•¨
        return seg_idx