import numpy as np
from scipy.sparse.csgraph import minimum_spanning_tree
from sklearn.neighbors import kneighbors_graph
from scipy.spatial.distance import pdist, squareform
from scipy.stats import chi2
import logging
from datetime import datetime
import copy
import pandas as pd
import subprocess
import json
import sys, os
import math
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from typing import List, Tuple, Iterable, Set
from sklearn.metrics.pairwise import euclidean_distances
from itertools import chain, repeat, combinations
from heapq import nsmallest
from math import ceil
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))
from utils.visualize import plot_tree_layout_custom, plot_segment_tree
from data.dataGenerator import generate_single_data, generate_multi_data
from scipy.sparse import find
import torch

from math import ceil, floor, log2
from utils.r_utils import compute_g_stat_from_graph
@dataclass
class CPStat:          # (cp, G) í•œ ìŒ
    cp: int
    G: float

class gBottomup:
    def __init__(self, encoder: torch.nn.Module,  config: dict, start_with=0, num_cp=1, alpha=0.05, isnan=0,
                c=2, isFullTree=True, eliminate='both',  visualize=False, model_timestamp=None, logger_timestamp=None):
        """
        Parameters:
        ----------
            encoder: torch.nn.Module
                TCN-AutoEncoderì˜ ì¸ì½”ë” ë¶€ë¶„
            config: dict
                gBottomup ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            start_with: int
                ì‹œì‘ ì¸ë±ìŠ¤, ë°ì´í„°ì˜ ì‹œì‘ index, python ê³„ì—´ 0, R 1
            model_type: str
                ëª¨ë¸ ì¢…ë¥˜, base, local, max, step 
            num_cp: int
                BLR ìœ„í•´ì„œ ì‚¬ìš©ë˜ëŠ” CPì˜ ê°œìˆ˜
            min_obs: int
                ì´ˆê¸° ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°
            merge_percentile: float
                ë³‘í•©í•  windowë¥¼ ì„ íƒí•˜ê¸° ìœ„í•œ G í†µê³„ëŸ‰ì˜ ë°±ë¶„ìœ„ìˆ˜ (0~1 ì‚¬ì´ì˜ ê°’)
                ì˜ˆ: 0.1ì´ë©´ í•˜ìœ„ 10% G í†µê³„ëŸ‰ì„ ê°€ì§„ windowë¥¼ ì„ íƒí•˜ì—¬ ë³‘í•©
            alpha: int or None
                ìœ ì˜ìˆ˜ì¤€ (ê¸°ë³¸ê°’ 0.05), threshold ê³„ì‚°ì— ì‚¬ìš©   
            isnan: int
                NaNì„ infë¡œ ë³€í™˜í• ì§€ ì—¬ë¶€
                - 0: NaNì„ 0ìœ¼ë¡œ ë³€í™˜
                - 1: NaNì„ infë¡œ ë³€í™˜
            c: int
                BIC ê³„ì‚° ì‹œ ì‚¬ìš©ë˜ëŠ” ìƒìˆ˜
            isFullTree: bool
                ì „ì²´ íŠ¸ë¦¬ë¥¼ ëê¹Œì§€ ë§Œë“¤ì§€, early stop í—ˆìš©í• ì§€ ì—¬ë¶€
            eliminate: str
                - 'forward': forward elimination
                - 'backward': backward elimination
                - 'both': forward + backward(backward elimination í›„ forward elimination)
                - 'none': ìµœì¢… 1ê°œë§Œ ë±‰ìŒ

            visualize: bool
                ë³‘í•©ê³¼ì • ì‹œê°í™” ì—¬ë¶€
            
            model_timestamp: str
                ëª¨ë¸ ì´ë¦„ì— í¬í•¨ë  íƒ€ì„ìŠ¤íƒ¬í”„
            
            logger_timestamp: str
                ë¡œê±° ì´ë¦„ì— í¬í•¨ë  íƒ€ì„ìŠ¤íƒ¬í”„
        """
        np.seterr(divide='ignore', invalid='ignore')
        self.encoder = encoder
        self.config = config
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.encoder.to(self.device)
        self.n_thread = self.config.get('num_threads', os.cpu_count())


        self.min_obs = config.get('min_obs', 4)
        self.merge_percentile = config.get('merge_percentile', 0.1)

        self.start_with = start_with
        self.num_cp = num_cp
        self.alpha = alpha
        self.isnan = isnan
        self.isFullTree = isFullTree
        self.eliminate = eliminate

        self.visualize = visualize
        
        self.seg_history: List[List[List[int]]] = []

        self.model_timestamp = model_timestamp if model_timestamp is not None else datetime.now().strftime("%Y%m%d_%H%M%S")
        self.logger_timestamp = logger_timestamp

        if self.alpha is not None:
            df = 2  # ììœ ë„ ì„¤ì • (chi2 ë¶„í¬ì— ì‚¬ìš©)
            self.CRITICAL = chi2.ppf(1 - self.alpha, df)
        
        self.c = c  # BIC ê³„ì‚° ì‹œ ì‚¬ìš©ë˜ëŠ” ìƒìˆ˜
        self.merge_history: List[List[CPStat]] = []
        self.actual_merges_history: List[List[int]] = []
        self._is_first_step = True


    def sliding_windows(self, seg_idx):
        """
        seg_idx: list of segments index
        return:
            list of windows with segments indices
            - [[0, 1], [2, 3], ...] í˜•íƒœë¡œ ê° windowì— í¬í•¨ëœ segmentì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        windows = []
        seg_idx = [seg for seg in seg_idx if len(seg) > 0]
        n = len(seg_idx)
        stride = 1
        visited = set()

        for start_idx in range(n - 1):
            current_window = []
            obs_count = 0
            segment_count = 0
            window_segment_indices = []

            for idx in range(start_idx, n, stride):
                cur_idx = seg_idx[idx]
                current_window.append(cur_idx)
                window_segment_indices.append(idx)  # âœ… segmentì˜ ìœ„ì¹˜ ì¸ë±ìŠ¤ë¥¼ ì¶”ì 

                obs_count += len(cur_idx)
                segment_count += 1

                if segment_count >= 2:
                    windows.append(current_window.copy())
                    visited.update(window_segment_indices)  # âœ… ê´€ì¸¡ê°’ì´ ì•„ë‹Œ segment index ê¸°ë¡
                    break

        remaining = [seg_idx[i] for i in range(n) if i not in visited]

        remaining = [seg_idx[i] for i in range(n) if i not in visited]
        flat_remaining = list(chain.from_iterable(remaining))  # [198, 199, ...]

        if flat_remaining:
            if windows:
                # ë§ˆì§€ë§‰ ìœˆë„ìš°ì˜ ë§ˆì§€ë§‰ segmentì— ë¶™ì´ê¸°
                windows[-1][-1].extend(flat_remaining)
            else:
                # ìœˆë„ìš°ê°€ ì•„ì˜ˆ ì—†ì—ˆë‹¤ë©´ ìƒˆë¡œ ì‹œì‘
                windows.append([flat_remaining])
        try: 
            windows = sorted(windows, key=lambda w: w[0][0] if w and len(w[0]) > 0 else float('inf'))
        except:
            pass
        
        return windows  # ìœˆë„ìš°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
    def get_t(self, window_indices):
        """
        ì£¼ì–´ì§„ segment ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° t, n1, n2ë¥¼ ê³„ì‚°í•œë‹¤.
        Parameters:
            index_lst: list of segments
                - [[1], [2], [3,4,5], [6], [7]] í˜•íƒœì˜ segmentì˜ index ë¦¬ìŠ¤íŠ¸
        
        Returns:
            t: int
                - group1ì˜ ë§ˆì§€ë§‰ observation index (0-based)
            n1: int
                - group1ì˜ ê´€ì¸¡ì¹˜ ìˆ˜
            n2: int
                - group2ì˜ ê´€ì¸¡ì¹˜ ìˆ˜
        """
        index_lst= window_indices.copy()  # ì›ë³¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šë„ë¡ ë³µì‚¬
        # Step 1:segment ê²½ê³„ ìœ„ì¹˜ êµ¬í•˜ê¸° (ëˆ„ì í•©)
        segment_sizes = [len(segment) for segment in index_lst]

        cumulative_sizes = np.cumsum(segment_sizes) 
        n = int(cumulative_sizes[-1])
        t = int(cumulative_sizes[0])-1  # indexë¡œ ë§ì¶¤, 0 basedë¼ 1ëºŒ
        n1 = int(cumulative_sizes[0])  # group1ì˜ ê´€ì¸¡ì¹˜ ìˆ˜
        n2 = n - n1
        return t, n1, n2

            
    def build_graph(self, observations, graph_type='mst', eliminate=True, min_window_length=None):
        """
        ê´€ì¸¡ê°’ìœ¼ë¡œë¶€í„° k-graphë¥¼ êµ¬ì¶•í•˜ê³  ê·¸ë˜í”„ë¥¼ ë°˜í™˜í•œë‹¤.

        Parameters:
            observations: list of vectors (n x d)
                - ê´€ì¸¡ê°’ ë¦¬ìŠ¤íŠ¸
            k: int
                - ëª‡ ë²ˆ MSTë¥¼ ê²°í•©í• ì§€

        Returns:
            edges: list of (i, j)
                - k-graph ëˆ„ì ëœ edge ë¦¬ìŠ¤íŠ¸
            weights: list of float
                - rank_typeì´ ì£¼ì–´ì¡Œì„ ë•Œ edgeë³„ ê°€ì¤‘ì¹˜ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ None)
        """
        observations = np.array(observations)
        n = observations.shape[0]      
        #kê°’ì˜ ìµœëŒ€ê°’ ì„¤ì •
        # këŠ” n//2-1ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•¨, ì™„ì „ê·¸ë˜í”„ë¥¼ ë§Œë“¤ì§€ ëª»í•˜ë„ë¡ ì œí•œ(mstì˜ ê²½ìš° N/2ë¡œ ìµœëŒ€ê°€ ì œí•œë¨, nngëŠ” n-1ê°œ)
        if min_window_length is not None:
            step_n = min(n, min_window_length)  # ìµœì†Œ ìœˆë„ìš° ê¸¸ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ê·¸ ê¸¸ì´ë¡œ ì œí•œ
        else:
            step_n = n  # í˜„ì¬ ìœˆë„ìš° ê¸¸ì´ë¡œ ì„¤ì •
        
        # kê°’ ì„¤ì •
        # 30 ìƒí•œ
        if graph_type == 'mst':
            # ì—¬ëŸ¬ k í›„ë³´ ê°’ë“¤ì„ ê³„ì‚°
            k_candidate1 = int(np.sqrt(step_n))
            k_candidate2 = (step_n) // 2 - 1
            k = min(30, k_candidate1, k_candidate2)

        # eliminate ì‹œì—ëŠ” segment í¬ê¸°ì— ìƒê´€ì—†ì´ ìµœëŒ€ 5ë¡œ ì œí•œ
        if eliminate:
            k_candidate1 = int(np.sqrt(step_n))
            k_candidate2 = (step_n) // 2 - 1
            k = min(5, k_candidate1, k_candidate2)

        k = max(1, k)  # këŠ” ìµœì†Œ 1ë¡œ ì„¤ì •

        # Step 1: ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
        dist = euclidean_distances(observations) 
        # dist = squareform(pdist(observations, metric='mahalanobis'))
        sim = -dist

        used = np.zeros((n, n))  # ì‚¬ìš©ëœ edge ê¸°ë¡
        edge_to_level = dict()   # (i,j): level ê¸°ë¡

        all_edges = []  #ë°˜í™˜í•  edge ë¦¬ìŠ¤íŠ¸, ëˆ„ì  edge 

        for level in range(1, k+1):
            # Step 2: í˜„ì¬ê¹Œì§€ ì‚¬ìš©ë˜ì§€ ì•Šì€ edgeë§Œ ê³ ë ¤
            effective_dist = np.where(used == 0, dist, 1e8)

            if graph_type == 'mst':
                # Step 3: MST ë§Œë“¤ê¸° (ìµœëŒ€ ìœ ì‚¬ë„ MST)
                # ë¬´ë°©í–¥ê·¸ë˜í”„, ë‹¨ symmetricì€ ì•„ë‹˜
                mst = minimum_spanning_tree(effective_dist)  # ìµœì†Œ ê±°ë¦¬ë¥¼ ìµœëŒ€ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                mst = mst.toarray()
                graph = mst
                

            elif graph_type == 'nng':
                nng = kneighbors_graph(effective_dist, 1, mode='connectivity', include_self=False).toarray()
                n = nng.shape[0]
                # ì–‘ë°©í–¥ì¸ ì—£ì§€ ì°¾ì•„ì„œ í•œ ë°©í–¥ë§Œ retain
                for i in range(n):
                    for j in range(i + 1, n):  # i < jë§Œ í™•ì¸í•˜ë©´ ì¤‘ë³µ ì—†ìŒ
                        if nng[i, j] == 1 and nng[j, i] == 1:
                            nng[j, i] = 0  # jâ†’i ë°©í–¥ ì œê±°
                graph = nng


            # Step 4: í˜„ì¬ ê·¸ë˜í”„ edge ì¶”ì¶œ ë° ê¸°ë¡(Kêµ¬í˜„ìœ„í•´ì„œ)
            rows, cols, _ = find(graph)

            # 0ì´ ì•„ë‹Œ ì—£ì§€ë“¤ë§Œ ìˆœíšŒ
            for i, j in zip(rows, cols):
                all_edges.append((i, j))
                edge_to_level[(i,j)] = level
                used[i,j] = 1
                used[j,i] = 1
                        

        E = np.array(all_edges, dtype=int)  # (i, j) í˜•íƒœì˜ edge ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        E += 1  # Rê³¼ í˜¸í™˜ë˜ë„ë¡ 1-based ì¸ë±ì‹±ìœ¼ë¡œ ë³€í™˜
        return E

    ############# G í†µê³„ëŸ‰ ê³„ì‚° #############   
    def compute_G(self, window_indices, eliminate=False, min_window_length=None):
        """
        ì£¼ì–´ì§„ window(segments ë¬¶ìŒ)ë¡œë¶€í„° G í†µê³„ëŸ‰ ê³„ì‚°
        Parameters:
            window: List[List[int]]
                - ì‹¤ì œ ê°’ì„ ë‹´ê³  ìˆëŠ” window
                (ì˜ˆ: [[1], [2], [3,4,5], [6], [7]])
            window_indices: List[List[int]]
                - segmentì˜ index ë¦¬ìŠ¤íŠ¸
                (ì˜ˆ: [[0], [1], [2,3,4], [5], [6]])
        Returns:
            G: float
                - statistic ê°’ 
        ì¤‘ìš”í•œì ì€ Segmentë§ˆë‹¤ indexê°€ ë°”ë€Œì–´ì•¼í•¨(ë°”ë€ŒëŠ”ì¤‘)
        """

        #Step 1: t, n1, n2, cp, window êµ¬ì„±
        # t: group1ì˜ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤, n1: group1ì˜ ê´€ì¸¡ê°’ ìˆ˜, n2: group2ì˜ ê´€ì¸¡ê°’ ìˆ˜
        # window_indices_flat: ëª¨ë“  segmentì˜ ì¸ë±ìŠ¤ë¥¼ 1ì°¨ì›ìœ¼ë¡œ flatten

        t, n1, n2 = self.get_t(window_indices)  # t, n1, n2 ê³„ì‚° 
        n = n1 + n2
        window_indices_flat = list(chain.from_iterable(window_indices))  # flatten
        window_data = self.observations[window_indices_flat, :]
        cp = window_indices_flat[t]

        if self._is_first_step:
            # ì²« ìŠ¤í…: ì›ë³¸ ë°ì´í„°(raw data)ë¡œ ê·¸ë˜í”„ ìƒì„±
            observation = window_data
        else:
            # ì´í›„ ìŠ¤í…: ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ë³€í™˜ í›„ ê·¸ë˜í”„ ìƒì„±
            observation = self._embed_data(window_data)

        #Step 2: K-MST ê·¸ë˜í”„ ìƒì„±, Edge ë¦¬ìŠ¤íŠ¸ E ìƒì„±
        E = self.build_graph(observations=observation, graph_type='mst', eliminate=eliminate, min_window_length=min_window_length)


        #Step 3: R gsegíŒ¨í‚¤ì§€ ì‹¤í–‰í•´ì„œ G í†µê³„ëŸ‰ ê³„ì‚°
        St = compute_g_stat_from_graph(n, E, t)

        if not self.isnan:
            #error handling
            St = np.nan_to_num(St, nan=0, posinf=0, neginf=0)
        else: 
            St = np.nan_to_num(St, nan=np.inf, posinf=np.inf, neginf=np.inf) # NaNì„ infë¡œ ë³€í™˜

        return CPStat(cp=cp, G=St)


    def merge_segments_sequential(self,
            all_windows: List[List[List[int]]],
            all_stats: List[CPStat],
            candidate_indices: List[int]
            ) -> List[List[int]]:
            """
            ê·œì¹™ì— ë”°ë¼ ìˆœì°¨ì ìœ¼ë¡œ, ê²¹ì¹¨ ì—†ì´ ìœˆë„ìš°ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.

            1. ë³‘í•© í›„ë³´ë“¤ì„ G í†µê³„ëŸ‰ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
            2. Gê°’ì´ ê°€ì¥ ë‚®ì€ í›„ë³´ë¶€í„° ìˆœì„œëŒ€ë¡œ ë³‘í•©ì„ ì‹œë„í•©ë‹ˆë‹¤.
            3. í•œ ë²ˆ ë³‘í•©ì— ì‚¬ìš©ëœ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ëŠ” í•´ë‹¹ ë‹¨ê³„ì˜ ë‹¤ë¥¸ ë³‘í•©ì— ì¬ì‚¬ìš©ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
            
            Args:
                all_windows: í˜„ì¬ ë‹¨ê³„ì˜ ëª¨ë“  ìœˆë„ìš° ë¦¬ìŠ¤íŠ¸.
                all_stats: í˜„ì¬ ë‹¨ê³„ì˜ ëª¨ë“  CPStat ê°ì²´ ë¦¬ìŠ¤íŠ¸.
                candidate_indices: ë³‘í•© í›„ë³´ê°€ ë˜ëŠ” ìœˆë„ìš°ë“¤ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (í•˜ìœ„ 10% ë“±).

            Returns:
                ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°ˆ ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸.
            """
            
            # 1. ë³‘í•© í›„ë³´ë¥¼ (Gê°’, ìœˆë„ìš°) í˜•íƒœë¡œ ë§Œë“¤ì–´ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            merge_candidates = []
            for i in candidate_indices:
                # íŠœí”Œ: (G í†µê³„ëŸ‰, ë³‘í•©ë  ìœˆë„ìš° êµ¬ì¡°)
                merge_candidates.append((all_stats[i].G, all_windows[i]))
            
            # Gê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            merge_candidates.sort(key=lambda x: x[0])

            # 2. í˜„ì¬ ë‹¨ê³„ì˜ ëª¨ë“  ê³ ìœ í•œ ê¸°ë³¸(base) ì„¸ê·¸ë¨¼íŠ¸ë¥¼ setìœ¼ë¡œ ì¤€ë¹„
            all_base_segments_set: Set[Tuple[int, ...]] = set()
            for window in all_windows:
                for segment in window:
                    all_base_segments_set.add(tuple(sorted(segment)))

            # 3. ìˆœì°¨ì  ë³‘í•© ìˆ˜í–‰
            # ì´ë²ˆ ë‹¨ê³„ì—ì„œ ë³‘í•©ì— ì‚¬ìš©ë˜ì–´ ì‚¬ë¼ì§ˆ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ì¶”ì 
            segments_to_remove: Set[Tuple[int, ...]] = set()
            # ë³‘í•©ì˜ ê²°ê³¼ë¡œ ìƒˆë¡œ ìƒì„±ë  ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ì €ì¥
            newly_created_segments: List[List[int]] = []

            for _, window_to_merge in merge_candidates:
                # í˜„ì¬ í›„ë³´ ìœˆë„ìš°ë¥¼ êµ¬ì„±í•˜ëŠ” ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ë“¤ (íŠœí”Œ í˜•íƒœ)
                candidate_base_segs = {tuple(sorted(seg)) for seg in window_to_merge}

                # ì´ í›„ë³´ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ì´ë¯¸ ë³‘í•©ì— ì‚¬ìš©ë˜ì—ˆë‹¤ë©´ ê±´ë„ˆë›°ê¸°
                # isdisjoint: ë‘ setì´ ê²¹ì¹˜ëŠ” ì›ì†Œê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ True ë°˜í™˜
                if not candidate_base_segs.isdisjoint(segments_to_remove):
                    continue

                # --- ìœ íš¨í•œ ë³‘í•©ì´ë¯€ë¡œ ìˆ˜í–‰ ---
                # 1) ì´ í›„ë³´ì˜ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ 'ì œê±° ëª©ë¡'ì— ì¶”ê°€í•˜ì—¬ ì´í›„ ì¬ì‚¬ìš© ë°©ì§€
                segments_to_remove.update(candidate_base_segs)
                
                # 2) ì‹¤ì œë¡œ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ 'ì‹ ê·œ ìƒì„± ëª©ë¡'ì— ì¶”ê°€
                merged_list = [node for seg in window_to_merge for node in seg]
                newly_created_segments.append(sorted(list(set(merged_list))))

            # 4. ìµœì¢… ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ ì¡°í•©
            # ê¸°ì¡´ì˜ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ, ì´ë²ˆì— ë³‘í•©ì— ì‚¬ìš©ëœ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ëº€ë‹¤
            final_segments_set = all_base_segments_set - segments_to_remove
            
            # setì„ ë‹¤ì‹œ list of listsë¡œ ë³€í™˜
            final_segments = [list(seg) for seg in final_segments_set]
            # ìƒˆë¡œ ìƒì„±ëœ ë³‘í•© ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ì¶”ê°€
            final_segments.extend(newly_created_segments)
            
            # ì‹œì‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë°˜í™˜
            return sorted(final_segments, key=lambda x: x[0])
    

    def select_cps_by_connected_rule(self) -> List[int]:
        if not self.merge_history:
            return []

        # 1. G > Î» ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë“  'Seed CP' ì°¾ê¸°
        seed_cps = set()
        for stats_list in self.merge_history:
            for stat in stats_list:
                if stat.G > self.CRITICAL:
                    seed_cps.add(stat.cp)

        final_cps = set(seed_cps)              
        return sorted(list(final_cps))
    
    def select_merge_indices_rank(
        self,
        cp_stats_now: List, # CPStat íƒ€ì…ìœ¼ë¡œ ê°€ì •
        merge_percentile: float | None = None,
    ) -> List[int]:
        """
        G-ê°’ì˜ 'ìˆœìœ„'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•  cpì˜ 'ì¸ë±ìŠ¤'ë¥¼ ê³ ë¥¸ë‹¤.
        (ë™ì  ì²˜ë¦¬ ê·œì¹™ ì¶”ê°€: ì»¤íŠ¸ë¼ì¸ì— í•´ë‹¹í•˜ëŠ” ë™ì  ê°’ì€ ëª¨ë‘ í¬í•¨)

        Parameters
        ----------
        cp_stats_now : List[CPStat]
            ì´ë²ˆ stepì˜ CP-í†µê³„ëŸ‰
        merge_percentile : float, optional
            0~1 ì‚¬ì´ : í•˜ìœ„ ëª‡ %ë¥¼ ë³‘í•©í• ì§€. (ì˜ˆ: 0.20 â†’ í•˜ìœ„ 20 %)
            Noneì¼ ê²½ìš° ê¸°ë³¸ê°’(self.DEFAULT_MERGE_PERCENTILE)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

        Returns
        -------
        List[int]
            ë³‘í•© ëŒ€ìƒ change-pointì˜ ì›ë³¸ ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤ (ì˜¤ë¦„ì°¨ìˆœ)
        """
        if not cp_stats_now:
            return []

        # -------- 0) ë§¤ê°œë³€ìˆ˜ ìœ íš¨ì„± ê²€ì‚¬ ë° ê¸°ë³¸ê°’ ì„¤ì • --------
        if merge_percentile is None:
            merge_percentile = self.merge_percentile
        
        # -------- 1) ëª‡ ê°œë¥¼ ìë¥¼ì§€ ê²°ì • ---------------------------------
        n = len(cp_stats_now)
        k = ceil(n * merge_percentile) if n > 0 else 0
        if k == 0:
            return []
        
        # kê°€ ì „ì²´ ê°œìˆ˜ë³´ë‹¤ í´ ìˆ˜ ì—†ë„ë¡ ë³´ì •
        k = min(k, n)

        # -------- 2) G ê¸°ì¤€ ì „ì²´ ì •ë ¬ ë° ì»¤íŠ¸ë¼ì¸(G-ê°’) ê²°ì • --------
        # enumerateë¥¼ ì‚¬ìš©í•˜ì—¬ (ì›ë³¸ ì¸ë±ìŠ¤, CPStat ê°ì²´) ìŒì„ ë§Œë“­ë‹ˆë‹¤.
        # G-ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•©ë‹ˆë‹¤.
        sorted_stats_with_indices = sorted(
            enumerate(cp_stats_now), 
            key=lambda x: x[1].G
        )

        # kë²ˆì§¸ í•­ëª©ì˜ G-ê°’ì„ ì»¤íŠ¸ë¼ì¸ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. (0-based indexì´ë¯€ë¡œ k-1)
        cutoff_g_value = sorted_stats_with_indices[k-1][1].G

        # -------- 3) ì»¤íŠ¸ë¼ì¸ê³¼ ë™ì ìë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ í›„ë³´ ì„ ì • --------
        # G-ê°’ì´ ì»¤íŠ¸ë¼ì¸ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ ëª¨ë“  í•­ëª©ì„ í›„ë³´ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
        # sorted()ëŠ” ì•ˆì •ì (stable)ì´ë¯€ë¡œ, G-ê°’ì´ ê°™ì„ ê²½ìš° ì›ë˜ ìˆœì„œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        candidates_with_stats = []
        for index, stat in sorted_stats_with_indices:
            if stat.G <= cutoff_g_value:
                candidates_with_stats.append((index, stat))
            else:
                # ë¦¬ìŠ¤íŠ¸ê°€ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì»¤íŠ¸ë¼ì¸ë³´ë‹¤ í° ê°’ì´ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨í•´ë„ ë©ë‹ˆë‹¤.
                break

        # -------- 4) Full-tree ì—¬ë¶€/CRITICAL ê°’ ë°˜ì˜ ----------------------
        if not self.isFullTree:
            final_candidates = [
                index for index, stat in candidates_with_stats
                if stat.G < self.CRITICAL
            ]
        else:
            final_candidates = [index for index, stat in candidates_with_stats]

        # -------- 5) ìµœì¢… ê²°ê³¼ ë°˜í™˜ --------------------------------------
        return sorted(final_candidates)

    def select_merge_indices_local_min(self, cp_stats_now: List[CPStat], window_size: int = 3) -> List[int]:
        """
        ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ì‚¬ìš©í•˜ì—¬ G-í†µê³„ëŸ‰ì˜ ì§€ì—­ ìµœì†Œê°’(local minima)ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

        Args:
            cp_stats_now (List[CPStat]): í˜„ì¬ ë³‘í•© ë‹¨ê³„ì˜ CPStat ê°ì²´ ë¦¬ìŠ¤íŠ¸.
            window_size (int): ìµœì†Œê°’ì„ ì°¾ê¸° ìœ„í•œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ì˜ í¬ê¸°.

        Returns:
            List[int]: ë³‘í•© ëŒ€ìƒìœ¼ë¡œ ì„ íƒëœ CPStat ê°ì²´ì˜ ì›ë³¸ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ëœ ìœ ë‹ˆí¬ ê°’).
        """
        # ì…ë ¥ê°’ì´ ë¹„ì–´ìˆê±°ë‚˜ window_sizeê°€ ë¶€ì ì ˆí•œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not cp_stats_now or window_size <= 0:
            return []

        num_stats = len(cp_stats_now)
        # ìœˆë„ìš° í¬ê¸°ê°€ ì „ì²´ ë¦¬ìŠ¤íŠ¸ í¬ê¸°ë³´ë‹¤ í´ ê²½ìš°, ì „ì²´ì—ì„œ ìµœì†Œê°’ì„ ì°¾ë„ë¡ ì¡°ì •
        if window_size > num_stats:
            window_size = num_stats
            
        local_min_indices = set()

        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ì´ë™ì‹œí‚¤ë©° ë°˜ë³µ
        for i in range(num_stats - window_size + 1):
            window = cp_stats_now[i : i + window_size]

            # í˜„ì¬ ìœˆë„ìš°ì—ì„œ G-í†µê³„ëŸ‰ì˜ ìµœì†Œê°’ì„ ì°¾ìŒ
            min_g_in_window = min(stat.G for stat in window)

            # ìœˆë„ìš° ë‚´ì—ì„œ ìµœì†Œê°’ê³¼ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  CPStatì„ ì°¾ìŒ
            for j, stat in enumerate(window):
                if stat.G == min_g_in_window:
                    # ì›ë³¸ ë¦¬ìŠ¤íŠ¸ì—ì„œì˜ ì¸ë±ìŠ¤(i + j)ë¥¼ ê²°ê³¼ ì§‘í•©ì— ì¶”ê°€
                    local_min_indices.add(i + j)

        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return sorted(list(local_min_indices))
    
    ############# Unmerge ë¡œì§ #############

    def _calculate_g_for_unmerge(self, segments_to_test: List[List[int]], min_len: None) -> float:
        """
        Unmerge ë¡œì§ì„ ìœ„í•œ G-í†µê³„ëŸ‰ ê³„ì‚° í—¬í¼ ë©”ì†Œë“œ.
        ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ G-í†µê³„ëŸ‰ ê°’ì„ ë°˜í™˜í•œë‹¤.
        Parameters:
            segments_to_test: List[List[int]]
                - G-í†µê³„ëŸ‰ì„ ê³„ì‚°í•  ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
            min_len: int
                - k-MST ê·¸ë˜í”„ ìƒì„± ì‹œ ê³ ë ¤í•  ìµœì†Œ ìœˆë„ìš° ê¸¸ì´
        Returns:
            G: float
                - ê³„ì‚°ëœ G-í†µê³„ëŸ‰ ê°’
        """
        # ë°ì´í„°ê°€ ì—†ëŠ” ë¹ˆ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ê³„ì‚°ì—ì„œ ì œì™¸
        valid_segments = [seg for seg in segments_to_test if seg]
        if len(valid_segments) < 2:
            return 0.0 if not self.isnan else np.inf

        # compute_G ë©”ì†Œë“œì— í•„ìš”í•œ í˜•íƒœë¡œ ë°ì´í„° ê°€ê³µ
        window_indices_flat = list(chain.from_iterable(valid_segments))
        window_data = [self.observations[i] for i in window_indices_flat]
        
        # compute_GëŠ” CPStat ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ .G ì†ì„±ì„ ì¶”ì¶œ
        stat = self.compute_G(valid_segments, min_window_length=min_len)
        return stat.G

    def _perform_unmerge_pass(self, seg_idx: List[List[int]]) -> List[List[int]]:
        """
        Unmerge ë¡œì§ì„ ì•ˆì •í™”ë  ë•Œê¹Œì§€ ë°˜ë³µ ìˆ˜í–‰.
        ë¶„ë¦¬/ì¬ë³‘í•© íš¨ìš© ì ìˆ˜ê°€ ì–‘ìˆ˜ì¸ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´, ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìˆœìœ¼ë¡œ ìˆœì°¨ì ìœ¼ë¡œ unmergeë¥¼ ì§„í–‰í•œë‹¤.
        í•œ ë²ˆì˜ unmerge í›„ ë³€ê²½ëœ ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡°ë¥¼ ì¦‰ì‹œ ë°˜ì˜í•˜ì—¬ ë‹¤ì‹œ ìµœì ì˜ unmerge ëŒ€ìƒì„ ì°¾ëŠ”ë‹¤.
        """
        # ì•ˆì •í™”ë  ë•Œê¹Œì§€ ë£¨í”„ ë°˜ë³µ
        while True:
            unmerge_candidates = []
            
            # 1. í˜„ì¬ seg_idx ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  unmerge í›„ë³´ì™€ ì ìˆ˜ ê³„ì‚°
            #    ì–‘ ì˜†ì— ì´ì›ƒì´ ìˆëŠ” ì„¸ê·¸ë¨¼íŠ¸(ì¸ë±ìŠ¤ 1ë¶€í„° N-2ê¹Œì§€)ë¥¼ ìˆœíšŒ
            for i in range(1, len(seg_idx) - 1):
                seg_A, seg_B, seg_C = seg_idx[i-1], seg_idx[i], seg_idx[i+1]
                
                if len(seg_B) < 2: continue

                split_point = len(seg_B) // 2
                seg_B1, seg_B2 = seg_B[:split_point], seg_B[split_point:]
                
                # min_len ê³„ì‚°
                min_len = min(len(seg_A) + len(seg_B1), len(seg_B2) + len(seg_C), len(seg_B1) + len(seg_B2))
                # min_len = None
                # G-í†µê³„ëŸ‰ ê³„ì‚°
                g_keep = self._calculate_g_for_unmerge([seg_B1, seg_B2], min_len)
                g_split_left = self._calculate_g_for_unmerge([seg_A, seg_B1], min_len)
                g_split_right = self._calculate_g_for_unmerge([seg_B2, seg_C], min_len)
                
                # "min of difference" ê·œì¹™ì„ ì ìˆ˜ë¡œ ì‚¬ìš©
                score_left = g_keep - g_split_left
                score_right = g_keep - g_split_right
                unmerge_score = min(score_left, score_right)
                
                if unmerge_score > 0:
                    unmerge_candidates.append((unmerge_score, i))
            
            # 2. Unmerge ëŒ€ìƒì´ ë” ì´ìƒ ì—†ëŠ”ì§€ í™•ì¸
            if not unmerge_candidates:
                # ì•ˆì •í™” ìƒíƒœì— ë„ë‹¬í–ˆìœ¼ë¯€ë¡œ ë£¨í”„ ì¢…ë£Œ
                break
                
            # 3. ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìµœì„  ëŒ€ìƒì„ ì°¾ì•„ Unmerge ì‹¤í–‰
            unmerge_candidates.sort(key=lambda x: x[0], reverse=True)
            best_score, best_idx = unmerge_candidates[0]
            
            # ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            seg_A, seg_B, seg_C = seg_idx[best_idx - 1], seg_idx[best_idx], seg_idx[best_idx + 1]
            
            split_point = len(seg_B) // 2
            new_seg_left = seg_A + seg_B[:split_point]
            new_seg_right = seg_B[split_point:] + seg_C
            
            # seg_idxë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ë‹¤ìŒ ë£¨í”„ ì´í„°ë ˆì´ì…˜ì— ë°˜ì˜
            seg_idx = seg_idx[:best_idx-1] + [new_seg_left, new_seg_right] + seg_idx[best_idx+2:]
            
            print(f"Unmerge performed at index {best_idx} -> new indices {best_idx-1}, {best_idx}. Score: {best_score:.4f}")

        # ëª¨ë“  unmergeê°€ ì™„ë£Œë˜ì–´ ì•ˆì •í™”ëœ seg_idx ë°˜í™˜
        return seg_idx
    
    def set_encoder(self, encoder: torch.nn.Module):
            """ì™¸ë¶€(Trainer)ì—ì„œ ì—…ë°ì´íŠ¸ëœ ì¸ì½”ë”ë¥¼ ì£¼ì…ë°›ê¸° ìœ„í•œ ë©”ì†Œë“œ."""
            self.encoder = encoder
            self.encoder.to(self.device)
            print("[gBottomup] New encoder received and updated.")

    def _embed_data(self, window_data: np.ndarray) -> np.ndarray:
        """ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í˜„ì¬ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•´ ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        self.encoder.eval()
        with torch.no_grad():
            tensor_data = torch.from_numpy(window_data).float().unsqueeze(0).to(self.device)
            embedded_tensor = self.encoder(tensor_data)
            return embedded_tensor.squeeze(0).cpu().numpy()

    def fit(self, data: np.ndarray):
        """
        Unmerge ê²€ì¦ì„ í¬í•¨í•œ ìµœì¢… ë‹¨ê³„ë³„ ì ì‘í˜• í•™ìŠµì„ ìœ„í•œ fit ë©”ì†Œë“œ.
        """
        self.observations = data
        n, _ = data.shape
        self._is_first_step = True

        # 1. ì´ˆê¸° ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ë° ì‚¬ì „ Unmerge (Raw data ê¸°ë°˜)
        # ì´ ë‹¨ê³„ëŠ” ì„ë² ë”© í•™ìŠµ ì „ì— ì‹¤í–‰ë˜ì–´ ì´ˆê¸° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì•ˆì •í™”í•©ë‹ˆë‹¤.
        print("--- Starting Pre-Merge & Unmerge Phase (based on raw data) ---")
        seg_idx = [list(range(i, min(i + self.min_obs, n))) for i in range(0, n, self.min_obs)]
        self.seg_history.append([s.copy() for s in seg_idx])
        
        # num_unmerge_steps = floor(log2(n))
        # for i in range(num_unmerge_steps):
        #     print(f"Pre-unmerge Pass {i+1}/{num_unmerge_steps}...")
        #     seg_idx = self._perform_unmerge_pass(seg_idx) 
        #     self.seg_history.append([s.copy() for s in seg_idx])
        
        print("--- Pre-Merge & Unmerge Phase Complete ---")

        # 2. ë©”ì¸ íƒìƒ‰-í•™ìŠµ ìˆœí™˜ ë£¨í”„
        while len(seg_idx) > 1:
            window_indices = self.sliding_windows(seg_idx)
            if not window_indices: break

            window_lst = [[[self.observations[idx] for idx in sublist] for sublist in group] for group in window_indices]
            # window_lstì˜ ê° windowë¥¼ 2D numpy ë°°ì—´ë¡œ ë³€í™˜
            window_lst_np = [np.vstack([np.array(sublist) for sublist in group]) for group in window_lst]

            min_window_length = min(sum(len(seg) for seg in w) for w in window_indices) if window_indices else 0

            cp_stats_now = [self.compute_G(win_idx, False, min_window_length) 
                            for window, win_idx in zip(window_lst_np, window_indices)]

            # 2.2. ë³‘í•©í•  í›„ë³´(ê¸ì • ìŒ) ì‹ë³„
            candidate_indices = self.select_merge_indices_rank(cp_stats_now)
            if not candidate_indices: break
            
            # 2.3. ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ìˆ˜í–‰
            # ì–´ë–¤ ìœˆë„ìš°ê°€ ë³‘í•©ë˜ì—ˆëŠ”ì§€ ì¶”ì í•˜ê¸° ìœ„í•´ ë³‘í•© ì „ ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡° ì €ì¥
            positive_pairs_before_unmerge = candidate_indices.copy()

            seg_idx_after_merge = self.merge_segments_sequential(window_indices, cp_stats_now, positive_pairs_before_unmerge)

            # # 2.4. ë³‘í•© í›„ Unmerge ê²€ì¦ ë‹¨ê³„
            # # ì´ ë‹¨ê³„ëŠ” ë°©ê¸ˆ ë³‘í•©ëœ ì„¸ê·¸ë¨¼íŠ¸ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤.
            # print("Performing post-merge unmerge check...")
            # seg_idx_after_unmerge = self._perform_unmerge_pass(seg_idx_after_merge)
            # self.seg_history.append([s.copy() for s in seg_idx_after_unmerge])

            # 2.5. ğŸ”¥ Unmergeëœ ê¸ì • ìŒ í•„í„°ë§
            # Unmerge ê³¼ì •ì—ì„œ ë‹¤ì‹œ ë¶„ë¦¬ëœ ìŒì€ "ì˜ëª»ëœ" ê¸ì • ìŒì´ë¯€ë¡œ í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
            # valid_positive_pairs = []
            # unmerged_set = {tuple(map(tuple, s)) for s in seg_idx_after_unmerge}

            # for pair in positive_pairs_before_unmerge:
            #     pair_tuple = tuple(map(tuple, pair))
            #     if pair_tuple not in unmerged_set:
            #         valid_positive_pairs.append(pair)
            #     else:
            #         print(f"Invalidated a positive pair due to unmerge: {pair}")
            
            # 2.6. ğŸ”¥ ìœ íš¨í•œ ê¸ì • ìŒë§Œ Trainerì—ê²Œ ì „ë‹¬í•˜ê³  ëª¨ë¸ ì—…ë°ì´íŠ¸ ê¸°ë‹¤ë¦¼
            valid_positive_pairs = positive_pairs_before_unmerge
            new_encoder = yield valid_positive_pairs
            if new_encoder is not None:
                self.set_encoder(new_encoder)
            
            # 2.7. ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•´ ìƒíƒœ ì—…ë°ì´íŠ¸
            self._is_first_step = False
            seg_idx = seg_idx_after_merge

            return valid_positive_pairs