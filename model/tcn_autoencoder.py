import torch
import torch.nn as nn

class TCNBlock(nn.Module):
    """
    TCN(Temporal Convolutional Network)ì˜ ê¸°ë³¸ êµ¬ì„± ë¸”ë¡ì…ë‹ˆë‹¤.
    Causal Convolutionì„ ì ìš©í•˜ì—¬ ì‹œê°„ì  ìˆœì„œë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.
    """
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 4, dilation: int = 1, dropout: float = 0.2):
        """
        Args:
            in_channels (int): ì…ë ¥ ì±„ë„ì˜ ìˆ˜.
            out_channels (int): ì¶œë ¥ ì±„ë„ì˜ ìˆ˜.
            kernel_size (int): ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ì˜ í¬ê¸°.
            dilation (int): ì»¨ë³¼ë£¨ì…˜ì˜ íŒ½ì°½(dilation) ì •ë„.
            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨.
        """
        super().__init__()
        
        # Causal Convolutionì„ ìœ„í•´ í•„ìš”í•œ íŒ¨ë”© ê³„ì‚°
        self.padding = (kernel_size - 1) * dilation
        
        # 1D ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
        self.conv1 = nn.Conv1d(
            in_channels, out_channels, kernel_size,
            padding=self.padding, dilation=dilation
        )
        # Weight Normalization ì ìš©
        self.conv1 = nn.utils.weight_norm(self.conv1)
        
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)
        
        # Residual connectionì„ ìœ„í•œ 1x1 conv (ì±„ë„ ìˆ˜ê°€ ë‹¤ë¥¼ ê²½ìš°)
        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None
        self.relu_out = nn.ReLU()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x (torch.Tensor): ì…ë ¥ í…ì„œ (Batch, Channels, Length)

        Returns:
            torch.Tensor: TCN ë¸”ë¡ì˜ ì¶œë ¥ í…ì„œ (Batch, Channels, Length)
        """
        # ì»¨ë³¼ë£¨ì…˜ ë° í™œì„±í™” í•¨ìˆ˜ ì ìš©
        out = self.conv1(x)
        
        # Causal Convolution: ë¯¸ë˜ì˜ ì •ë³´ê°€ í˜„ì¬ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ ëë¶€ë¶„ì„ ì˜ë¼ëƒ„
        out = out[:, :, :-self.padding]
        out = self.relu1(out)
        out = self.dropout1(out)

        # Residual connection (ì”ì°¨ ì—°ê²°)
        res = x if self.downsample is None else self.downsample(x)
        
        return self.relu_out(out + res)


class TCNEncoder(nn.Module):
    """
    TCN ë¸”ë¡ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ì˜ í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¸ì½”ë”ì…ë‹ˆë‹¤.
    """
    def __init__(self, in_channels: int, embedding_dim: int, hidden_channels: int, depth: int = 3, kernel_size: int = 4):
        """
        Args:
            in_channels (int): ì…ë ¥ ì‹œê³„ì—´ì˜ ë³€ìˆ˜ ì°¨ì›.
            embedding_dim (int): ì¶œë ¥ ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›.
            hidden_channels (int): TCN ë¸”ë¡ ë‚´ë¶€ì˜ ì€ë‹‰ ì±„ë„ ìˆ˜.
            depth (int): TCN ë¸”ë¡ì„ ìŒ“ì„ ê¹Šì´.
            kernel_size (int): ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ì˜ í¬ê¸°.
        """
        super().__init__()
        
        layers = []
        current_channels = in_channels
        
        # TCN ë¸”ë¡ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” dilationê³¼ í•¨ê»˜ ìŒ“ìŒ
        for i in range(depth):
            dilation = 2**i
            layers.append(
                TCNBlock(
                    current_channels, hidden_channels, 
                    kernel_size=kernel_size, dilation=dilation
                )
            )
            current_channels = hidden_channels
            
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ëŠ” ìµœì¢… ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ ë§¤í•‘
        layers.append(nn.Conv1d(current_channels, embedding_dim, 1))
        
        self.network = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        ğŸ”¥ í•µì‹¬: Temporal Poolingì„ ì ìš©í•˜ì§€ ì•Šì•„ í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            x (torch.Tensor): ì…ë ¥ í…ì„œ (Batch, Length, Channels_in)

        Returns:
            torch.Tensor: í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ (Batch, Length, Channels_out)
        """
        # (B, L, C) -> (B, C, L) í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ Conv1dì— ì…ë ¥
        x = x.permute(0, 2, 1)
        
        embedding_sequence = self.network(x)
        
        # (B, C, L) -> (B, L, C) í˜•íƒœë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return embedding_sequence.permute(0, 2, 1)


class TCNDecoder(nn.Module):
    """
    í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ ì›ë³¸ ì‹œê³„ì—´ì„ ì¬êµ¬ì„±í•˜ëŠ” ë””ì½”ë”ì…ë‹ˆë‹¤.
    ì¸ì½”ë”ì™€ ëŒ€ì¹­ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
    """
    def __init__(self, embedding_dim: int, out_channels: int, hidden_channels: int, depth: int = 3, kernel_size: int = 4):
        """
        Args:
            embedding_dim (int): ì…ë ¥ ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›.
            out_channels (int): ì¶œë ¥ ì‹œê³„ì—´ì˜ ë³€ìˆ˜ ì°¨ì›.
            hidden_channels (int): TCN ë¸”ë¡ ë‚´ë¶€ì˜ ì€ë‹‰ ì±„ë„ ìˆ˜.
            depth (int): TCN ë¸”ë¡ì„ ìŒ“ì„ ê¹Šì´.
            kernel_size (int): ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ì˜ í¬ê¸°.
        """
        super().__init__()

        layers = []
        current_channels = embedding_dim
        
        # TCN ë¸”ë¡ì„ ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•˜ëŠ” dilationê³¼ í•¨ê»˜ ìŒ“ìŒ (ì¸ì½”ë”ì˜ ì—­ìˆœ)
        for i in range(depth - 1):
            dilation = 2**(depth - 1 - i)
            layers.append(
                TCNBlock(
                    current_channels, hidden_channels, 
                    kernel_size=kernel_size, dilation=dilation
                )
            )
            current_channels = hidden_channels
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ëŠ” dilationì´ 1ì¸ TCN ë¸”ë¡
        layers.append(TCNBlock(current_channels, hidden_channels, kernel_size=kernel_size, dilation=1))
        
        # ìµœì¢… ì¶œë ¥ ì±„ë„ë¡œ ë§¤í•‘
        layers.append(nn.Conv1d(hidden_channels, out_channels, 1))

        self.network = nn.Sequential(*layers)

    def forward(self, z: torch.Tensor) -> torch.Tensor:
        """
        Args:
            z (torch.Tensor): í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ (Batch, Length, Channels_in)

        Returns:
            torch.Tensor: ì¬êµ¬ì„±ëœ ì‹œê³„ì—´ í…ì„œ (Batch, Length, Channels_out)
        """
        # (B, L, C) -> (B, C, L) í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ Conv1dì— ì…ë ¥
        z = z.permute(0, 2, 1)
        
        reconstructed_sequence = self.network(z)
        
        # (B, C, L) -> (B, L, C) í˜•íƒœë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return reconstructed_sequence.permute(0, 2, 1)


class TCNAutoEncoder(nn.Module):
    """
    TCN ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê²°í•©í•œ ìµœì¢… AutoEncoder ëª¨ë¸ì…ë‹ˆë‹¤.
    """
    def __init__(self, in_channels: int, embedding_dim: int = 16, hidden_channels: int = 64, depth: int = 3, kernel_size: int = 4):
        """
        Args:
            in_channels (int): ì…ë ¥ ì‹œê³„ì—´ì˜ ë³€ìˆ˜ ì°¨ì›.
            embedding_dim (int): ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›.
            hidden_channels (int): TCN ë¸”ë¡ ë‚´ë¶€ì˜ ì€ë‹‰ ì±„ë„ ìˆ˜.
            depth (int): TCN ë¸”ë¡ì˜ ê¹Šì´.
            kernel_size (int): ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ì˜ í¬ê¸°.
        """
        super().__init__()
        self.encoder = TCNEncoder(in_channels, embedding_dim, hidden_channels, depth, kernel_size)
        self.decoder = TCNDecoder(embedding_dim, in_channels, hidden_channels, depth, kernel_size)

    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """
        ëª¨ë¸ì˜ ìˆœì „íŒŒ ë¡œì§.

        Args:
            x (torch.Tensor): ì›ë³¸ ì‹œê³„ì—´ í…ì„œ (Batch, Length, Channels)

        Returns:
            z (torch.Tensor): í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ (Batch, Length, embedding_dim)
            x_recon (torch.Tensor): ì¬êµ¬ì„±ëœ ì‹œê³„ì—´ í…ì„œ (Batch, Length, Channels)
        """
        # 1. ì¸ì½”ë”ë¥¼ í†µí•´ í¬ì¸íŠ¸ë³„ ì„ë² ë”© ì‹œí€€ìŠ¤ zë¥¼ ìƒì„±
        z = self.encoder(x)
        
        # 2. ë””ì½”ë”ë¥¼ í†µí•´ zë¡œë¶€í„° ì›ë³¸ ì‹œê³„ì—´ x_reconì„ ì¬êµ¬ì„±
        x_recon = self.decoder(z)
        
        return z, x_recon