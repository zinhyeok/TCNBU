import torch
import numpy as np
import yaml
import os
from typing import Dict, Any

# í”„ë¡œì íŠ¸ì˜ ë‹¤ë¥¸ ëª¨ë“ˆë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from models.tcn_autoencoder import TCNEncoder # AutoEncoder ì „ì²´ê°€ ì•„ë‹Œ Encoderë§Œ í•„ìš”
from models.g_bottomup import gBottomup
from data.generator import generate_multi_data # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ì„ ìœ„í•´ ì„ì‹œ ì‚¬ìš©
# from models.model_selector import ModelSelector # ìµœì¢… CP ì„ íƒ ë¡œì§ (êµ¬í˜„ í•„ìš”)

def load_config(config_path: str = './configs/default_config.yaml') -> Dict[str, Any]:
    """YAML ì„¤ì • íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜."""
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    return config

def load_trained_encoder(config: Dict[str, Any]) -> TCNEncoder:
    """
    ì‚¬ì „ í›ˆë ¨ëœ TCNEncoder ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.

    Args:
        config (Dict[str, Any]): ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° ê°€ì¤‘ì¹˜ ê²½ë¡œ ì •ë³´ê°€ ë‹´ê¸´ ì„¤ì • ë”•ì…”ë„ˆë¦¬.

    Returns:
        TCNEncoder: ê°€ì¤‘ì¹˜ê°€ ë¡œë“œëœ ì¸ì½”ë” ëª¨ë¸ ê°ì²´.
    """
    model_config = config['model']
    encoder = TCNEncoder(
        in_channels=model_config['in_channels'],
        embedding_dim=model_config['embedding_dim'],
        hidden_channels=model_config['hidden_channels'],
        depth=model_config['depth'],
        kernel_size=model_config['kernel_size']
    )
    
    model_path = config['data']['model_save_path']
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Trained model not found at {model_path}. Please run main_train.py first.")
        
    print(f"Loading pre-trained encoder weights from: {model_path}")
    # CPU í™˜ê²½ì—ì„œë„ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ map_location ì„¤ì •
    encoder.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    encoder.eval() # ëª¨ë¸ì„ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •
    
    return encoder

def main():
    """ë©”ì¸ ë³€í™”ì  íƒì§€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜."""
    
    # 1. ì„¤ì • íŒŒì¼ ë¡œë“œ
    print("Loading configuration...")
    config = load_config()

    # 2. íƒì§€í•  ìƒˆë¡œìš´ ë°ì´í„° ìƒì„± ë˜ëŠ” ë¡œë“œ
    # ì—¬ê¸°ì„œëŠ” ì‹œì—°ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.
    print("Generating new data for detection...")
    test_data, true_change_points = generate_multi_data(
        n=500, # í•™ìŠµ ë°ì´í„°ë³´ë‹¤ ì§§ì€ ê¸¸ì´ë¡œ ì„¤ì •
        d=config['model']['in_channels'],
        scenario='model15' # ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
    )
    print(f"Test data generated with shape: {test_data.shape}")
    print(f"True change points are at: {true_change_points}")

    # 3. ì‚¬ì „ í›ˆë ¨ëœ ì¸ì½”ë” ëª¨ë¸ ë¡œë“œ
    encoder = load_trained_encoder(config)
    
    # 4. gBottomup ê°ì²´ ì´ˆê¸°í™” (í•™ìŠµëœ ì¸ì½”ë” ì£¼ì…)
    print("Initializing gBottomup with the pre-trained encoder...")
    # íƒì§€ ì‹œì—ëŠ” gBottomupì˜ 'eliminate' ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… CPë¥¼ ì„ íƒí•˜ë„ë¡ ì„¤ì •
    # config['gbottomup']['eliminate'] = 'both' # ì˜ˆ: BIC ê¸°ë°˜ ì„ íƒ
    g_bottomup_detector = gBottomup(encoder=encoder, config=config['gbottomup'])
    print("gBottomup detector initialized successfully.")

    # 5. ë³€í™”ì  íƒì§€ ì‹¤í–‰
    # ğŸ”¥ íƒì§€ ì‹œì—ëŠ” fit() ì œë„ˆë ˆì´í„°ë¥¼ ëê¹Œì§€ ì‹¤í–‰í•˜ë˜, ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ
    print("Starting change point detection process...")
    g_bottomup_generator = g_bottomup_detector.fit(test_data)
    
    try:
        while True:
            # generatorë¡œë¶€í„° ê¸ì • ìŒì„ ë°›ì§€ë§Œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            _ = next(g_bottomup_generator)
            # ì—…ë°ì´íŠ¸ëœ ì¸ì½”ë”ë¥¼ ë³´ë‚´ëŠ” ëŒ€ì‹  Noneì„ ë³´ëƒ„
            g_bottomup_generator.send(None)
    except StopIteration:
        print("\ngBottomup detection process finished.")

    # 6. ìµœì¢… ë³€í™”ì  ê²°ê³¼ ì²˜ë¦¬
    # gBottomupì˜ fit ë©”ì†Œë“œê°€ ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •í•˜ê±°ë‚˜,
    # merge_historyë¥¼ í›„ì²˜ë¦¬í•˜ì—¬ ìµœì¢… CPë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ ë³‘í•© í›„ë³´ë“¤ì„ ìµœì¢… í›„ë³´ë¡œ ê°„ì£¼í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    if g_bottomup_detector.merge_history:
        # ë§ˆì§€ë§‰ ë³‘í•© ë‹¨ê³„ì˜ CPë“¤ì„ í›„ë³´ë¡œ ì„ íƒ
        last_step_stats = g_bottomup_detector.merge_history[-1]
        candidate_cps = sorted([stat.cp for stat in last_step_stats])
        
        # ModelSelectorë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… CP ì„ íƒ (ì˜ˆì‹œ)
        # model_selector = ModelSelector(g_bottomup_detector)
        # estimated_cps, _ = model_selector.stepwise_elimination(candidate_cps)
        
        # ì—¬ê¸°ì„œëŠ” ê°€ì¥ G-ê°’ì´ í° (ê°€ì¥ ë³€í™”ê°€ ëšœë ·í•œ) 3ê°œë¥¼ ì„ íƒí•˜ëŠ” ì˜ˆì‹œ
        last_step_stats.sort(key=lambda s: s.G, reverse=True)
        estimated_cps = sorted([s.cp for s in last_step_stats[:3]])

    else:
        estimated_cps = []

    print("\n--- Detection Results ---")
    print(f"True Change Points:     {true_change_points}")
    print(f"Estimated Change Points:  {estimated_cps}")
    print("-------------------------")


if __name__ == '__main__':
    # R í™˜ê²½ ì´ˆê¸°í™”
    print("Initializing R environment...")
    try:
        from utils import r_utils
        r_utils.init_r_packages()
        print("R environment initialized successfully.")
    except Exception as e:
        print(f"Could not initialize R environment. Error: {e}")
        exit()

    main()